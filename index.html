<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <base href=".">
    <link rel="canonical" href="https://scai.swjtu.edu.cn/strl2025/">
    <link rel="shortcut icon" type="image/png" href="./assets/favicon.png">
    <link rel="stylesheet" type="text/css" media="all" href="./assets/main.css">
    
    <meta name="description" content="In this workshop, we invite the research community in artificial intelligence to submit works related to the integration of spatial and temporal reasoning with machine learning.">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Workshop, Reasoning, Learning, Spatio-Temporal Information">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="4th International Workshop on Spatio-Temporal Reasoning and Learning 2025">
    <meta name="twitter:description" content="In this workshop, we invite the research community in artificial intelligence to submit works related to the integration of spatial and temporal reasoning with machine learning.">
    <meta name="twitter:image" content="https://strl-workshop.github.io/strl2025/assets/banner.jpg">
    <meta property="og:title" content="4th International Workshop on Spatio-Temporal Reasoning and Learning 2025">
    <meta property="og:description" content="In this workshop, we invite the research community in artificial intelligence to submit works related to the integration of spatial and temporal reasoning with machine learning.">
    <meta property="og:image" content="https://strl-workshop.github.io/strl2025/assets/banner.jpg">
    <script type="text/javascript" async="" src="./assets/array.js"></script><script>
    !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.async=!0,p.src=s.api_host+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="capture identify alias people.set people.set_once set_config register register_once unregister opt_out_capturing has_opted_out_capturing opt_in_capturing reset isFeatureEnabled onFeatureFlags getFeatureFlag getFeatureFlagPayload reloadFeatureFlags group updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures getActiveMatchingSurveys getSurveys onSessionId".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
    posthog.init('phc_GJ4MC5B8nFstDrgNGu2kLOzivcKs1PHaU0a7IZlvrgg',{api_host:'https://eu.posthog.com', persistence: 'memory', disable_persistence: true})
    </script>
    <script src="https://kit.fontawesome.com/902731d579.js" crossorigin="anonymous"></script>
    <title>4th International Workshop on Spatio-Temporal Reasoning and Learning</title>
</head>

<body>
    <div class="banner">
        <img src="./assets/banner.jpg" alt="Workshop Banner" style="width: 100%">
        <div class="top-left">
            <span class="title1">4<sup>th</sup> International Workshop on </span> <br><br>
            <span class="title2">Spatio-Temporal Reasoning</span> <br><br>
            <span class="title2">and Learning</span> <br><br>
            <span class="year">16 August 2025</span> <br>
        </div>
        <div class="bottom-right">
          co-located with <a href="https://2025.ijcai.org/" target="_blank">IJCAI 2025</a>
        </div>
    </div>

    <table class="navigation">
        <tbody><tr>
            <td class="navigation">
                <a title="Workshop Program" href="#Program">Program</a> 
            </td>
            <td class="navigation">
                <a title="Call For Papers" href="#CFP">CFP</a>
            </td>
            <td class="navigation">
                <a title="Important Dates" href="#Dates">Dates</a>
            </td>
            <td class="navigation">
                <a title="Organization" href="#Organization">Organization</a>
            </td>
            <td class="navigation">
                <a title="Venue" href="#Venue">Venue</a>
            </td>
        </tr>
    </tbody></table>

    <h2>Introduction</h2>
    
    <p>Opposing the false dilemma of logical reasoning vs machine learning, we argue for a synergy between these two paradigms in order to obtain hybrid AI systems that will be robust, generalizable, and transferable.</p> 
    <p>Indeed, it is well-known that machine learning only includes statistical information and, therefore, is not <em>inherently</em> able to capture perturbations (interventions or changes in the environment), or perform reasoning and planning. Ideally, (the training of) machine learning models should be tied to assumptions that align with physics and human cognition to allow for these models to be re-used and re-purposed in novel scenarios.</p> 
    <p>On the other hand, it is also the case that logic in itself can be brittle too, and logic further assumes that the symbols with which it can reason are already given.</p> 
    <p>It is becoming ever more evident in the literature that modular AI architectures should be prioritized, where the involved knowledge about the world and the reality that we are operating in is decomposed into independent and recomposable pieces, as such an approach should only increase the chances that these systems behave in a causally sound manner.</p>
 
    <p>You may find details about previous editions of this workshop via the links below:</p>

    <ul>
    <li><a target="_blank" href="https://www.lirmm.fr/strl2024/">STRL 2024</a></li>
    <li><a target="_blank" href="https://codesign-lab.org/strl23/">STRL 2023</a></li>
    <li><a target="_blank" href="https://strl2022.github.io/">STRL 2022</a></li>
    </ul> 
    
    <h3>Objective</h3>
    
    <p>The aim of this workshop is to formalize such a synergy between logical reasoning and machine learning that will be grounded on spatial and temporal knowledge.</p> 
    <p>We argue that the calculi associated with the spatial and temporal reasoning community, be it qualitative or quantitative, naturally build upon physics and human cognition, and could therefore form a module that would be beneficial towards causal representation learning. A (symbolic) spatio-temporal knowledge base could provide a dependable <em>causal seed</em> upon which machine learning models could generalize, and exploring this direction from various perspectives is the main theme here.</p>
    
    <p><a href="#top">Go back to the top</a></p>
    
    
    <h2 id="CFP">Call For Papers</h2>
    
    <h3>Topics</h3>
    
    <p>In this workshop, we invite the research community in artificial intelligence to submit works related to the proposed integration of spatial and temporal reasoning with machine learning, revolving around the following topic areas:</p>
    <ul>
    <li>Real-world problems / applications involving spatio-temporal data</li>
    <li>Spatial, temporal, and spatio-temporal knowledge graphs</li>
    <li>Spatio-temporal data mining / analysis</li>
    <li>Space and time in narratives</li>
    <li>Declarative spatial reasoning</li>
    <li>Spatial and temporal language understanding with and without additional modalities (e.g., vision)</li>
    <li>(Multimodal) large language models (LLMs) and spatiotemporal reasoning</li>
    <li>Neuro-symbolic approaches for spatio-temporal reasoning and learning</li>
    <li>Probabilistic world models for spatio-temporal reasoning and learning</li>
    <li>Probabilistic inference for spatio-temporal reasoning and learning</li>
    <li>Datasets for spatio-temporal reasoning and learning</li>
    <li>Metrics for assessing spatio-temporal reasoning and learning methods</li>
    <li>Limitations in machine learning for spatio-temporal reasoning and learning; how far can machine learning go?</li>
    <li>Relation between causal reasoning and spatial and temporal reasoning</li>
    <li>Spatio-temporal awareness / reasoning in embodied intelligence (EI)</li>
    <li>Research and teaching challenges in spatio-temporal reasoning and learning</li>
    </ul> 
    <p>The list above is by no means exhaustive, as the aim is to foster the debate around all aspects of the suggested integration.</p>
    <p>Application domains being addressed include, but are not limited to:</p>
    <ul>
    <li>Autonomous Vehicles and Drones</li>
    <li>Cognitive Robotics</li>
    <li>Spatial Computing for Design</li>
    <li>Computational Art</li>
    <li>(Cognitive) Vision</li>
    <li>Geographic Information Systems</li>
    <li>Smart Environments</li>
    <li>Healthcare</li>
    </ul> 

    <h3>Submission</h3>
    
    <p><strong>The submission link is available at </strong> <a href="https://easychair.org/conferences/?conf=strl2025" target="_blank">easychair.org/conferences/?conf=strl2025</a>.

    <h4>Guidelines</h4>

    <p>Papers should be formatted according to the CEUR-ART style formatting guidelines <a target="_blank" href="./files/CEURART_STRL2025.zip">here</a> and submitted as a single PDF file.</p>
    <p>We welcome submissions across the full spectrum of theoretical and practical work including research ideas, methods, tools, simulations, applications or demos, practical evaluations, and surveys.</p> 
    <p>Submissions that are <em>2 pages long</em> (excluding references and appendices) will be considered for a <em>short presentation</em>, and submissions that are <em>between 4 and 7 pages long</em> (again, excluding references and appendices) will be considered for a <em>regular presentation</em>.</p> 
    <p>All papers will be peer-reviewed in a <em>single-blind</em> process and assessed based on their novelty, technical quality, potential impact, clarity, and reproducibility (when applicable). Extended abstracts of published papers are welcome, but they should demonstrate their close link to the topic of the workshop.</p>

    <p>All questions about submissions should be emailed to the organizers via strl2025 at easychair.org.</p>

    <h4 id="Dates">Important Dates</h4>
    <p>Be mindful of the following dates:</p>
    <ul>
    <li><s>April 25, 2025</s>&nbsp;<strong>May 9, 2025</strong>: Workshop paper submission deadline</li>
    <li><s>May 30, 2025</s>&nbsp;<strong>June 6, 2025</strong>: Paper acceptance/rejection notification date</li>
    <li><strong>June 13, 2025</strong>: Camera-ready submission deadline</li>
    <li><strong>August 16, 2025</strong>: Workshop Date</li>
    </ul> 
    <p><em><u>Note</u></em>: all deadlines are AoE (Anywhere on Earth).</p>
    
    <h3>Proceedings</h3>

    <!--<p>The accepted papers will appear on the workshop website. We also intend to publish the workshop proceedings with <a target="_blank" href="http://ceur-ws.org/">CEUR-WS.org</a>; this option will be discussed with the authors of accepted papers and is subject to the CEUR-WS.org preconditions. We note that, as STRL 2025 is a workshop, not a conference, submission of a revised and/or extended version of a paper to conferences or journals is acceptable from our standpoint.</p>-->

    <p>The back-link to the URL of the workshop proceedings published with CEUR-WS.org is now available at <a target="_blank" href="https://ceur-ws.org/Vol-4102/">https://ceur-ws.org/Vol-4102/</a>.
    
    <p><a href="#top">Go back to the top</a></p>
    
    
    <h2 id="Program">Workshop Program</h2>
    
    <h3>Speakers</h3>
    
    <table class="sponsors">
        <tr>
            <td class="sponsor">
                <a target="_blank" href="http://www.reirab.com/">
                    <img src="assets/reirab.jpg" alt="Asst. Prof. Reihaneh Rabbany" style="width: 100%; height: 100%">
                </a>
            </td>
            <td>                    
                    Prof. <a href="http://www.reirab.com/" target="_blank">Reihaneh Rabbany</a> is an assistant professor at the <a href="https://www.cs.mcgill.ca/" target="_blank">School of Computer Science</a> at <a href="https://www.mcgill.ca/" target="_blank">McGill University</a>, and a core academic member of <a href="https://mila.quebec/en" target="_blank">Mila – Quebec Artificial Intelligence Institute</a>. She is also a Canada <a href="https://cifar.ca/" target="_blank">CIFAR </a> AI Chair and on the faculty of McGill's Centre for the Study of Democratic Citizenship. Rabbany heads McGill's <a href="https://www.complexdatalab.com/" target="_blank">Complex Data Lab</a>, where she conducts research at the intersection of network science, data mining and machine learning, with a focus on analyzing real-world interconnected data and social good applications.
            </td>            
        </tr> 
        <tr>
            <td class="sponsor">
                <a target="_blank" href="https://people.tamu.edu/~xinli/">
                    <img src="assets/XinLi.jpg" alt="Prof. Xin (Shane) Li" style="width: 100%; height: 100%">
                </a>
            </td>
            <td>                    
                    Prof. <a href="https://people.tamu.edu/~xinli/" target="_blank">Xin (Shane) Li</a> is a Professor and Chair of the Section of Visual Computing and Computational Media with the <a href="https://pvfa.tamu.edu/" target="_blank">College of Performance, Visualization, & Fine Arts</a> at <a href="https://www.tamu.edu/" target="_blank">Texas A&M University</a> in Texas, USA. He is also a Joint Faculty member in the <a href="https://engineering.tamu.edu/cse/index.html" target="_blank">Department of Computer Science and Engineering, College of Engineering</a> and affiliated with the <a href="https://graphics.tamu.edu/" target="_blank">Aggie Computer Graphics Group</a>. His main research interests include visual computing (geometric/spatiotemporal data processing and modeling), computer vision and deep learning, generative AI for image/3D content generation, 3D reconstruction and VSLAM, computational forensics, and computer-aided design. <b style='color:red;'>Canceled.</b>
            </td>            
        </tr>  
        <tr>
            <td class="sponsor">
                <a target="_blank" href="https://experts.griffith.edu.au/7205-jun-zhou">
                    <img src="assets/junzhou.jpeg" alt="Prof. Jun Zhou" style="width: 100%; height: 100%">
                </a>
            </td>
            <td>                    
                    Prof. <a href="https://experts.griffith.edu.au/7205-jun-zhou" target="_blank">Jun Zhou</a> is a Professor and the Deputy Head of School (Research) of the <a href="https://www.griffith.edu.au/griffith-sciences/school-information-communication-technology" target="_blank">School of Information and Communication Technology</a> at <a href="https://www.griffith.edu.au/" target="_blank">Griffith University</a> in Queensland, Australia, where he is  also the Deputy Director of the ARC Hub for Driving Farming Productivity and Disease Prevention. His main research interests include hyperspectral imaging, computer vision, pattern recognition and their applications to remote sensing, agriculture, environment, and medicine.
            </td>            
        </tr>             
    </table>
    

    <h3>Schedule</h3>

    <table>
        <tr>
            <td class="date" rowspan="2">
                9:00
            </td>
            <td class="title-special">
                Opening: Welcome and Agenda
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="2">
                9:15
            </td>
            <td class="title">
                <em>Keynote:</em> Spectral-spatial-temporal Modelling for Hyperspectral Object Tracking
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Jun Zhou (Griffith University, Australia)
            </td>
        </tr>
    </table>    
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:15
            </td>
            <td class="title-special">
                Coffee &amp; Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                11:00
            </td>
            <td class="title">
                Multimodal Spatio-Temporal Vehicle Speed Prediction Using Hexagonal Grids in Santiago, Chile
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Diego Silva (Andr&eacute;s Bello National University, Santiago, Chile)<br>Billy Peralta (Andr&eacute;s Bello National University, Santiago, Chile)<br>Orietta Nicolis (Andr&eacute;s Bello National University, Santiago, Chile)<br>Andres Bronfman (Andr&eacute;s Bello National University, Santiago, Chile)<br>Luis Caro (Catholic University of Temuco, Chile)<br>Hans Lobel (Pontifical Catholic University of Chile, Santiago, Chile)
            </td>
        </tr>
    </table>  
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                11:30
            </td>
            <td class="title">
                Exploring Spatial Language Grounding Through Referring Expressions
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Akshar Tumu (University of California San Diego, USA)<br>Parisa Kordjamshidi (Michigan State University, USA)
            </td>
        </tr>
    </table>  

    <table>
        <tr>
            <td class="date" rowspan="2">
                12:00
            </td>
            <td class="title">
                Rule-Based Error Detection and Correction to Operationalize Movement Trajectory Classification
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Bowen Xi (Arizona State University, USA)<br>Kevin Scaria (Arizona State University, USA)<br>Divyagna Bavikadi (Syracuse University, USA)<br>Paulo Shakarian (Syracuse University, USA)
            </td>
        </tr>
    </table>   

    <table>
        <tr>
            <td class="date" rowspan="2">
                12:30
            </td>
            <td class="title-special">
                Lunch Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="2">
                14:00
            </td>
            <td class="title">
                <em>Keynote:</em> Building the Foundations of Temporal Graph Learning: Visualization, Evaluation, and Applications 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Reihaneh Rabbany (McGill University, Canada + Mila - Quebec AI Institute, Canada)
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:00
            </td>
            <td class="title">
                LoGo: Local-Global Context Modeling and Cross-Level Regression for Temporal Action Localization
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Li Xinxin (Chengdu Jincheng College, China)<br>Yang Zhe (Southwest Jiaotong University, China)
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                15:30
            </td>
            <td class="title-special">
                Coffee &amp; Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                16:15
            </td>
            <td class="title">
                HexaClus: Interpretable Hexagonal Supervised Spatial Clustering
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yameng Guo (Ghent University, Belgium)<br>Seppe vanden Broucke (Ghent University, Belgium + KU Leuven, Belgium)
            </td>
        </tr>
    </table> 
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                16:45
            </td>
            <td class="title">
                Multi-Level Pose-Guidance with Cross-Modality Fusion for Long-Term Spatio-Temporal Person Re-Identification | <a href="files/Multi-Level Pose-Guidance with Cross-Modality Fusion forLong-Term Spatio-Temporal Person Re-ldentification.mp4" target="_blank">video</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Qingyuan Deng (Sichuan Normal University, China)<br>Keyu Zhu (Sichuan Normal University, China)<br>Jindan Wu (Sichuan Normal University, China)<br>Xiaoning Li (Sichuan Normal University, China)<br>Xinxin Li (Chengdu Jincheng College, China)<br>Shihai He (Sichuan Mineral Electromechanic Technician College, China)<br>Lin Feng (Sichuan Normal University, China) 
            </td>
        </tr>
    </table>
 
    <table>
        <tr>
            <td class="date" rowspan="2">
                17:15
            </td>
            <td class="title">
                Final Remarks
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>        
    
    <table>
        <tr>
            <td class="date" rowspan="1">
                17:30
            </td>
            <td class="title-special">
                Closing
            </td>
        </tr>
    </table>

    <p><a href="#top">Go back to the top</a></p>

    
    <h2 id="Organization">Workshop Organization</h2>

    <h3>Organizing Committee</h3>
    
    <table class="sponsors">
        <tbody>
          <tr>
            <td class="sponsor">
                <a target="_blank" href="https://www.cse.msu.edu/~kordjams/">
                    <img src="./assets/parisa.png" alt="Prof. Parisa Kordjamshidi" style="width: 100%; height: 100%">
                </a>
            </td>
            <td>
                Prof. <a href="https://www.cse.msu.edu/~kordjams/" target="_blank">Parisa Kordjamshidi</a> is an Associate Professor
 with the  Department of Computer Science and Engineering of Michigan State University, US. Her main research interests are artificial intelligence, machine learning, natural language processing, and declarative learning based programming (DeLBP). Parisa is directing the research lab on <a href="https://hlr.github.io/" target="_blank">Heterogeneous Learning and Reasoning</a>. 
            </td>            
        </tr>
        <tr>
            <td class="sponsor">
                <a target="_blank" href="https://zhiguolong.github.io/">
                    <img src="./assets/zhiguo.jpg" alt="Assoc. Prof. Zhiguo Long" style="width: 100%; height: 100%">
                </a>
            </td>
            <td>
                Assoc. Prof. <a href="https://zhiguolong.github.io/" target="_blank">Zhiguo Long</a> is an Associate Professor with the School of Computing and Artificial Intelligence of the Southwest Jiaotong University, Chengdu, China. His research interests include fundamental and practical techniques in knowledge representation and reasoning, especially in qualitative spatial and temporal reasoning, and data representation and clustering in Machine Learning.
            </td>            
        </tr>  
        <tr>
            <td class="sponsor">
                <a target="_blank" href="https://jaeheelee.gitlab.io/">
                    <img src="./assets/jae.jpg" alt="Dr. Jae Hee Lee" style="width: 100%; height: 100%">
                </a>
            </td>
            <td>
                Dr. <a href="https://jaeheelee.gitlab.io/" target="_blank">Jae Hee Lee</a> is a Postdoctoral Research Associate with the Knowledge Technology Group, University of Hamburg, Germany. 
                His research aims to develop deep learning models for language understanding by leveraging multimodal information (e.g., vision, proprioception) with a particular focus on robustness and explainability.
            </td>            
        </tr>
        <tr>
          <td class="sponsor">
              <a target="_blank" href="https://faculty.swjtu.edu.cn/gongxun/en/index.htm">
                  <img src="./assets/xungong.jpg" alt="Prof. Xun Gong" style="width: 100%; height: 100%">
              </a>
          </td>
          <td>
              Prof. <a href="https://faculty.swjtu.edu.cn/gongxun/en/index.htm" target="_blank">Xun Gong</a> is a Professor and an Associate Dean of the School of Computing and Artificial Intelligence, Southwest Jiaotong University. He received the Ph.D. degree in computer science and technology from Southwest Jiaotong University in 2008. His research interests include pattern recognition, computer vision, medical image processing, and deep learning.
          </td>            
      </tr>  
      </tbody>
      </table>

    <h3>Advisory Committee</h3>
    
    <table class="sponsors">
        <tbody>
        <tr>
            <td class="sponsor">
                <a target="_blank" href="https://mehulbhatt.org/">
                    <img src="./assets/mehul.jpg" alt="Prof. Mehul Bhat" style="width: 100%; height: 100%">
                </a>
            </td>
            <td>
                Prof. <a href="https://mehulbhatt.org/" target="_blank">Mehul Bhatt</a> is a Professor of Computer Science with the School of Science and Technology at Örebro University, Sweden. His basic research focuses on formal, cognitive, and computational foundations for AI technologies with a principal emphasis on knowledge representation, semantics, integration of commonsense reasoning &amp; learning, explainability, and spatial representation and reasoning. Mehul steers <a href="https://codesign-lab.org/" target="_blank">CoDesign Lab</a>, and directs the research and consulting group <a href="https://www.design-space.org/" target="_blank">DesignSpace</a>. 
            </td>            
        </tr>
        <tr>
            <td class="sponsor">
                <a target="_blank" href="https://msioutis.gitlab.io/">
                    <img src="./assets/michael.jpg" alt="Prof. Michael Sioutis" style="width: 100%; height: 100%">
                </a>
            </td>
            <td>
                Prof. <a href="https://msioutis.gitlab.io/" target="_blank">Michael Sioutis</a> is a Junior Professor 
 of Hybrid AI with the Laboratory of Computer Science, Robotics, and Microelectronics of Montpellier and the Faculty of Sciences of the University of Montpellier, France. His general interests lie in artificial intelligence, knowledge representation and reasoning, data mining, logic programming, and semantic web.
            </td>            
        </tr>
    </tbody></table>    

    <h3>Program Committee</h3>

    <ul>
    <li><strong>Esra Erdem</strong>, Sabanc&#x131; University, Istanbul, Turkey <a href="https://people.sabanciuniv.edu/esraerdem/" target="_blank"><i class='fas fa-link'></i></a></li>
    <li><strong>Fangjun Li</strong>, University of Manchester, UK <a href="https://fangjun-li.github.io/" target="_blank"><i class='fas fa-link'></i></a></li>
    <li><strong>Kathleen Stewart</strong>, University of Maryland, US <a href="https://geog.umd.edu/facultyprofile/stewart/kathleen" target="_blank"><i class='fas fa-link'></i></a></li>
    <li><strong>Margot Geerts</strong>, KU Leuven, Belgium <a href="https://margotgeerts.github.io/" target="_blank"><i class='fas fa-link'></i></a></li>
    <li><strong>Sook-Ling Chua</strong>, Multimedia University, Cyberjaya, Malaysia <a href="https://mmuexpert.mmu.edu.my/slchua" target="_blank"><i class='fas fa-link'></i></a></li>
    <li><strong>Billy Peralta</strong>, Andr&#233;s Bello National University, Chile <a href="https://www.researchgate.net/profile/Billy-Peralta" target="_blank"><i class='fas fa-link'></i></a></li>        
    <li><strong>Irtaza	Khalid</strong>, Cardiff University, Wales <a href="https://www.cardiff.ac.uk/people/research-students/view/2501256-khalid-muhammad-irtaza" target="_blank"><i class='fas fa-link'></i></a></li>        
    <li><strong>Jie Feng</strong>, Tsinghua University, Beijing, China <a href="https://vonfeng.github.io/" target="_blank"><i class='fas fa-link'></i></a></li>
    <li><strong>Nassim Belmecheri</strong>, Simula Research Laboratory, Oslo, Norway <a href="https://www.simula.no/people/nassim" target="_blank"><i class='fas fa-link'></i></a></li>
    <li><strong>Anthony (Tony) G Cohn</strong>, University of Leeds, UK <a href="https://eps.leeds.ac.uk/computing/staff/76/professor-anthony-tony-g-cohn-freng-ceng-citp" target="_blank"><i class='fas fa-link'></i></a></li>
    <li><strong>Weiming Huang</strong>, University of Leeds, UK <a href="https://environment.leeds.ac.uk/geography/staff/13092/dr-weiming-huang" target="_blank"><i class='fas fa-link'></i></a></li>
    </ul>

    <p><a href="#top">Go back to the top</a></p>

    
    <h2 id="Venue">Venue</h2>
    
    <p>The workshop will take place in Montreal, Canada, co-located with <a href="https://2025.ijcai.org/" target="_blank">IJCAI 2025</a>; specifically, the worksop will take place at <strong>Room 516D</strong> at the <strong>Palais des congr&#232;s</strong> in Montreal, Canada.</p>

    <iframe class="directions" src="https://www.openstreetmap.org/export/embed.html?bbox=-73.56409370899202%2C45.50287673277435%2C-73.55736672878267%2C45.5067341330338&amp;layer=mapnik" width="800" height="600" style="border:0;" allowfullscreen="" loading="lazy"></iframe>

    <p><a href="https://www.openstreetmap.org/?#map=18/45.504805/-73.561401">View Larger Map</a></p>
    
    <p><a href="#top">Go back to the top</a></p>   

    <footer>
        © Workshop Organizers
        &nbsp;|&nbsp; Design by <a target="_blank" href="https://github.com/mikepierce">Mike Pierce</a>
        and <a target="_blank" href="http://ceur-ws.org/">CEUR-WS.org</a>
        &nbsp;|&nbsp; Banner photo by <a target="_blank" href="https://www.flickr.com/photos/vesiaphotography/">Michael Vesia</a> under <a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/2.0/">CC BY-NC-SA 2.0</a> <br> <br> <br> 
    </footer>


<script type="text/javascript" crossorigin="anonymous" src="./assets/config.js"></script></body></html>
